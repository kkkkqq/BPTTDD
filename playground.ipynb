{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((5,5)).requires_grad_(True)\n",
    "adam = Adam([a], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]], requires_grad=True)],\n",
       "  'lr': 0.1,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros((2,2)).requires_grad_(True)\n",
    "c = torch.zeros((2,2)).requires_grad_(True)\n",
    "adam.add_param_group({'params': [b, c], 'lr': 0.001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]], requires_grad=True)],\n",
       "  'lr': 0.1,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False},\n",
       " {'params': [tensor([[0., 0.],\n",
       "           [0., 0.]], requires_grad=True),\n",
       "   tensor([[0., 0.],\n",
       "           [0., 0.]], requires_grad=True)],\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a view of a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a view of a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "b[0][0]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.to('cpu')\n",
    "c.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "copygroup = copy.deepcopy(adam.param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]], requires_grad=True)],\n",
       "  'lr': 0.1,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False},\n",
       " {'params': [tensor([[0., 0.],\n",
       "           [0., 0.]], requires_grad=True)],\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copygroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[11., 11., 11., 11., 11.],\n",
       "           [11., 11., 11., 11., 11.],\n",
       "           [11., 11., 11., 11., 11.],\n",
       "           [11., 11., 11., 11., 11.],\n",
       "           [11., 11., 11., 11., 11.]], requires_grad=True)],\n",
       "  'lr': 0.1,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False},\n",
       " {'params': [tensor([[0., 0.],\n",
       "           [0., 0.]], requires_grad=True)],\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    copygroup[0]['params'][0].add_(5)\n",
    "copygroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]], requires_grad=True)],\n",
       "  'lr': 0.1,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False},\n",
       " {'params': [tensor([[0., 0.],\n",
       "           [0., 0.]], requires_grad=True)],\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    adam.param_groups[0]['params'][0][0]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad = torch.ones_like(a)\n",
    "b.grad = torch.ones_like(b)\n",
    "c.grad = torch.ones_like(c)\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[99.9000, 99.9000, 99.9000, 99.9000, 99.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000]], requires_grad=True)],\n",
       "  'lr': 0.1,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False},\n",
       " {'params': [tensor([[-0.0010, -0.0010],\n",
       "           [-0.0010, -0.0010]], requires_grad=True)],\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {tensor([[0.8000, 0.8000, 0.8000, 0.8000, 0.8000],\n",
       "                     [0.8000, 0.8000, 0.8000, 0.8000, 0.8000],\n",
       "                     [0.8000, 0.8000, 0.8000, 0.8000, 0.8000],\n",
       "                     [0.8000, 0.8000, 0.8000, 0.8000, 0.8000],\n",
       "                     [0.8000, 0.8000, 0.8000, 0.8000, 0.8000]], requires_grad=True): {'step': tensor(2.),\n",
       "              'exp_avg': tensor([[0.1900, 0.1900, 0.1900, 0.1900, 0.1900],\n",
       "                      [0.1900, 0.1900, 0.1900, 0.1900, 0.1900],\n",
       "                      [0.1900, 0.1900, 0.1900, 0.1900, 0.1900],\n",
       "                      [0.1900, 0.1900, 0.1900, 0.1900, 0.1900],\n",
       "                      [0.1900, 0.1900, 0.1900, 0.1900, 0.1900]]),\n",
       "              'exp_avg_sq': tensor([[0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n",
       "                      [0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n",
       "                      [0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n",
       "                      [0.0020, 0.0020, 0.0020, 0.0020, 0.0020],\n",
       "                      [0.0020, 0.0020, 0.0020, 0.0020, 0.0020]])},\n",
       "             tensor([[-0.0020, -0.0020],\n",
       "                     [-0.0020, -0.0020]], requires_grad=True): {'step': tensor(2.),\n",
       "              'exp_avg': tensor([[0.1900, 0.1900],\n",
       "                      [0.1900, 0.1900]]),\n",
       "              'exp_avg_sq': tensor([[0.0020, 0.0020],\n",
       "                      [0.0020, 0.0020]])},\n",
       "             tensor([[-0.0010, -0.0010],\n",
       "                     [-0.0010, -0.0010]], requires_grad=True): {'step': tensor(1.),\n",
       "              'exp_avg': tensor([[0.1000, 0.1000],\n",
       "                      [0.1000, 0.1000]]),\n",
       "              'exp_avg_sq': tensor([[0.0010, 0.0010],\n",
       "                      [0.0010, 0.0010]])}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.1,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0,\n",
       " 'amsgrad': False,\n",
       " 'maximize': False,\n",
       " 'foreach': None,\n",
       " 'capturable': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[99.9000, 99.9000, 99.9000, 99.9000, 99.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000],\n",
       "           [ 0.9000,  0.9000,  0.9000,  0.9000,  0.9000]], requires_grad=True)],\n",
       "  'lr': 0.1,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False},\n",
       " {'params': [tensor([[-0.0010, -0.0010],\n",
       "           [-0.0010, -0.0010]], requires_grad=True)],\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1\n",
      "b 1\n",
      "args: ()\n",
      "kwargs {}\n"
     ]
    }
   ],
   "source": [
    "def boo(a, *args, b=1, **kwargs):\n",
    "    print('a:', a)\n",
    "    print('b', b)\n",
    "    print('args:', args)\n",
    "    print('kwargs', kwargs)\n",
    "\n",
    "boo(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.detach().requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD([a], 0.01)\n",
    "a.grad = torch.zeros_like(a)\n",
    "sgd.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
